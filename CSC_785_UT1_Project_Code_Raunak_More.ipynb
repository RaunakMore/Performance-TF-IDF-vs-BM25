{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad069e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\rauna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rauna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rauna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import sent_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3099acc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the document from the Shakespeare's Macbeth corpus\n",
    "document = gutenberg.raw(\"shakespeare-macbeth.txt\")\n",
    "\n",
    "# Convert the document to lowercase\n",
    "document = document.lower()\n",
    "\n",
    "# Tokenize the document into sentences\n",
    "#sentences = nltk.sent_tokenize(document)\n",
    "# Tokenize the document into paragraphs\n",
    "sentences = nltk.tokenize.blankline_tokenize(document)\n",
    "# Create a SnowballStemmer object\n",
    "stemmer = SnowballStemmer('english')\n",
    "# Remove stopwords, punctuation, and any other irrelevant tokens\n",
    "# Preprocess each sentence and store the result in a list of documents\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "documents = []\n",
    "punctuation = list(string.punctuation)\n",
    "\n",
    "for sentence in sentences:\n",
    "    #Tokenize the sentence into words\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    filtered_words = [word for word in words if word not in punctuation not in stopwords and word.isalpha() ]\n",
    "    #print(filtered_words)\n",
    "    #Stem the words\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "    document = ' '.join(filtered_words)\n",
    "    #print(document)\n",
    "    documents.append(document)\n",
    "   \n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2532fd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_matrix shape is (678, 3310)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauna\\AppData\\Local\\Temp\\ipykernel_9528\\2534767209.py:55: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  bm25_matrix[i][j] = idf * (numerator / (denominator + epsilon))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF results:\n",
      "Query: three witch magic death thunder tragic\n",
      "Top 5 documents:\n",
      "1. thunder enter the three witches (score: 0.4877)\n",
      "2. thunder enter the three witches (score: 0.4877)\n",
      "3. thunder and lightning enter three witches (score: 0.4056)\n",
      "4. thunder enter the three witches meeting hecat (score: 0.3677)\n",
      "5. enter three murtherers (score: 0.2648)\n",
      "\n",
      "Query: knife wound red blood witch\n",
      "Top 5 documents:\n",
      "1. that my keene knife see not the wound it makes nor heauen peepe through the blanket of the darke to cry hold hold enter macbeth (score: 0.2415)\n",
      "2. macb it will haue blood they say blood will haue blood stones haue beene knowne to moue trees to speake augures and vnderstood relations haue by maggot pyes choughes rookes brought forth the man of blood what is the night la almost at oddes with morning which is which (score: 0.1492)\n",
      "3. macb whence is that knocking how with me when euery noyse appalls me what hands are here hah they pluck out mine eyes will all great neptunes ocean wash this blood cleane from my hand no this my hand will rather the multitudinous seas incarnardine making the greene one red enter lady (score: 0.1331)\n",
      "4. all the weyward sisters hand in hand posters of the sea and land thus doe goe about about thrice to thine and thrice to mine and thrice againe to make vp nine peace the charme wound vp enter macbeth and banquo (score: 0.0828)\n",
      "5. sister where thou a saylors wife had chestnuts in her lappe and mouncht mouncht and mouncht giue me quoth aroynt thee witch the ronyon cryes her husband to aleppo gone master tiger but in a syue ile thither sayle and like a rat without a tayle ile doe ile doe and ile doe (score: 0.0751)\n",
      "\n",
      "Query: ruthless ambit king propheci beast unmak fair\n",
      "Top 5 documents:\n",
      "1. banq you shall be king (score: 0.2174)\n",
      "2. king my worthy cawdor (score: 0.2112)\n",
      "3. king great happinesse (score: 0.1930)\n",
      "4. all haile king of scotland (score: 0.1893)\n",
      "5. rosse god saue the king (score: 0.1671)\n",
      "\n",
      "BM25 results:\n",
      "Query: three witch magic death thunder tragic\n",
      "Top 5 documents:\n",
      "1. thunder enter the three witches (score: 0.5033)\n",
      "2. thunder enter the three witches (score: 0.5033)\n",
      "3. thunder and lightning enter three witches (score: 0.3909)\n",
      "4. thunder enter the three witches meeting hecat (score: 0.3540)\n",
      "5. enter three murtherers (score: 0.2564)\n",
      "\n",
      "Query: knife wound red blood witch\n",
      "Top 5 documents:\n",
      "1. that my keene knife see not the wound it makes nor heauen peepe through the blanket of the darke to cry hold hold enter macbeth (score: 0.2850)\n",
      "2. macb whence is that knocking how with me when euery noyse appalls me what hands are here hah they pluck out mine eyes will all great neptunes ocean wash this blood cleane from my hand no this my hand will rather the multitudinous seas incarnardine making the greene one red enter lady (score: 0.1485)\n",
      "3. macb it will haue blood they say blood will haue blood stones haue beene knowne to moue trees to speake augures and vnderstood relations haue by maggot pyes choughes rookes brought forth the man of blood what is the night la almost at oddes with morning which is which (score: 0.1140)\n",
      "4. all the weyward sisters hand in hand posters of the sea and land thus doe goe about about thrice to thine and thrice to mine and thrice againe to make vp nine peace the charme wound vp enter macbeth and banquo (score: 0.1067)\n",
      "5. sister where thou a saylors wife had chestnuts in her lappe and mouncht mouncht and mouncht giue me quoth aroynt thee witch the ronyon cryes her husband to aleppo gone master tiger but in a syue ile thither sayle and like a rat without a tayle ile doe ile doe and ile doe (score: 0.0927)\n",
      "\n",
      "Query: ruthless ambit king propheci beast unmak fair\n",
      "Top 5 documents:\n",
      "1. banq you shall be king (score: 0.2171)\n",
      "2. king my worthy cawdor (score: 0.1891)\n",
      "3. all haile king of scotland (score: 0.1639)\n",
      "4. la what beast then that made you breake this enterprize to me when you durst do it then you were a man and to be more then what you were you would be so much more the man nor time nor place did then adhere and yet you would make both they haue made themselues and that their fitnesse now do vnmake you i haue giuen sucke and know how tender is to loue the babe that milkes me i would while it was smyling in my face haue pluckt my nipple from his bonelesse gummes and dasht the braines out had i so sworne as you haue done to this (score: 0.1576)\n",
      "5. king great happinesse (score: 0.1445)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a vocabulary of terms from the documents\n",
    "# Use a TfidfVectorizer to create a sparse matrix of term frequencies and inverse document frequencies\n",
    "# Store the vocabulary as a list of terms\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "print(\"tfidf_matrix shape is\", tfidf_matrix.shape)\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Compute the TF and IDF matrices for the documents\n",
    "# Use the TfidfVectorizer attributes to access the TF and IDF matrices\n",
    "# Convert them to numpy arrays for easier manipulation\n",
    "tf_matrix = tfidf_matrix.toarray()\n",
    "idf_matrix = vectorizer.idf_.reshape(-1, 1)\n",
    "\n",
    "# Define a query or a set of queries\n",
    "queries = [\n",
    "   \"three witches magic death thunder tragic\",\n",
    "   \"knife wound red blood witch\",\n",
    "   \"Ruthless ambition king prophecies beast unmake fair\"\n",
    "]\n",
    "\n",
    "# Preprocess the queries\n",
    "# Apply the same steps as the documents\n",
    "# Store the processed queries in a new list\n",
    "processed_queries = []\n",
    "for query in queries:\n",
    "    tokens = nltk.word_tokenize(query.lower())\n",
    "    stemmed = [stemmer.stem(token) for token in tokens if token not in punctuation not in stopwords and token.isalpha()]\n",
    "    processed_queries.append(' '.join(stemmed))\n",
    "\n",
    "# Define the parameters for the BM25 model\n",
    "k1 = 1.2\n",
    "b = 0.75\n",
    "epsilon = 0.25\n",
    "\n",
    "# Compute the average document length\n",
    "# Use the numpy function to calculate the mean of the sum of the term frequencies for each document\n",
    "avg_doc_len = np.mean(np.sum(tf_matrix, axis=1))\n",
    "\n",
    "# Compute the BM25 matrix for the documents\n",
    "# Store the BM25 matrix as a numpy array\n",
    "bm25_matrix = np.zeros_like(tf_matrix)\n",
    "for i in range(len(documents)):\n",
    "    doc_len = np.sum(tf_matrix[i])\n",
    "    for j in range(len(vocabulary)):\n",
    "        tf = tf_matrix[i][j]\n",
    "        idf = idf_matrix[j]\n",
    "        numerator = tf * (k1 + 1)\n",
    "        denominator = tf + k1 * (1 - b + b * doc_len / avg_doc_len)\n",
    "        bm25_matrix[i][j] = idf * (numerator / (denominator + epsilon))\n",
    "\n",
    "# Compute the similarity scores between the query and each document using the TF-IDF model\n",
    "# Use the cosine similarity function from sklearn to calculate the dot product of the query vector and the document vector\n",
    "# Store the similarity scores in a dictionary, where the key is the query and the value is a list of scores\n",
    "tfidf_similarity_scores = {}\n",
    "for query in processed_queries:\n",
    "    query_vector = vectorizer.transform([query]).toarray()\n",
    "    scores = cosine_similarity(query_vector, tf_matrix)[0]\n",
    "    tfidf_similarity_scores[query] = scores\n",
    "\n",
    "# Compute the similarity scores between the query and each document using the BM25 model\n",
    "# Use the same cosine similarity function as before\n",
    "# Store the similarity scores in a dictionary, where the key is the query and the value is a list of scores\n",
    "bm25_similarity_scores = {}\n",
    "for query in processed_queries:\n",
    "    query_vector = vectorizer.transform([query]).toarray()\n",
    "    scores = cosine_similarity(query_vector, bm25_matrix)[0]\n",
    "    bm25_similarity_scores[query] = scores\n",
    "\n",
    "# Rank the documents by their similarity scores using the TF-IDF model\n",
    "# Use the sorted function to sort the scores in descending order\n",
    "# Store the ranked documents in a dictionary, where the key is the query and the value is a list of document indices\n",
    "tfidf_ranked_documents = {}\n",
    "for query, scores in tfidf_similarity_scores.items():\n",
    "    ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "    tfidf_ranked_documents[query] = ranked_indices\n",
    "\n",
    "# Rank the documents by their similarity scores using the BM25 model\n",
    "# Use the same sorted function as before\n",
    "# Store the ranked documents in a dictionary, where the key is the query and the value is a list of document indices\n",
    "bm25_ranked_documents = {}\n",
    "for query, scores in bm25_similarity_scores.items():\n",
    "    ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "    bm25_ranked_documents[query] = ranked_indices\n",
    "\n",
    "# Return the top k documents for each query using the TF-IDF model\n",
    "# Define the value of k as the number of documents to return\n",
    "# Print the query and the top k documents with their scores\n",
    "k = 5\n",
    "print(\"TF-IDF results:\")\n",
    "for query, indices in tfidf_ranked_documents.items():\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Top {k} documents:\")\n",
    "    for i in range(k):\n",
    "        index = indices[i]\n",
    "        score = tfidf_similarity_scores[query][index]\n",
    "        document = documents[index]\n",
    "        print(f\"{i+1}. {document} (score: {score:.4f})\")\n",
    "    print()\n",
    "\n",
    "# Return the top k documents for each query using the BM25 model\n",
    "# Print the query and the top k documents with their scores\n",
    "print(\"BM25 results:\")\n",
    "for query, indices in bm25_ranked_documents.items():\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Top {k} documents:\")\n",
    "    for i in range(k):\n",
    "        index = indices[i]\n",
    "        score = bm25_similarity_scores[query][index]\n",
    "        document = documents[index]\n",
    "        print(f\"{i+1}. {document} (score: {score:.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3ccd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6e6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a924a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
